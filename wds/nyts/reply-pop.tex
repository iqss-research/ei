\documentclass[11pt]{article}
\usepackage{graphicx}

% using the same formatting as the paper:
\usepackage{times}
\usepackage{vmargin}
\setpapersize{USletter}
\setmarginsrb{1in}{1in}{1in}{0in}{0pt}{0mm}{0pt}{0mm}
\paperwidth=8.5in
\paperheight=11in
\topmargin=1.25in
\footskip=.5in
% \addtolength{\oddsidemargin}{-.55in}
% \addtolength{\evensidemargin}{-.55in}
% \addtolength{\textwidth}{1.1in}
% \addtolength{\textheight}{.9in}

\begin{document}

\begin{center}
  {\bf \Large Point-By-Point Reply to the Editor}
\end{center}

We begin by thanking Jennifer for her careful reading of our
manuscript and many helpful comments. We believe we have addressed all
of these comments in our revised manuscript and that in so doing we
have improved our paper a great deal.  In what follows, the original
comments appear in \emph{italic type}; our replies and comments are in
roman type.


\begin{enumerate}
\item {\it First, please cut the main text of the paper by about a
    quarter -- down to about 15 pp. from the current 22 pp.  In
    particular, much of the material about Bayesian model averaging
    could be cut. In conjunction with the cuts, please do all that you
    can with regard to most if not all of the equations to say in
    words what is now said symbolically. One of the missions of
    Perspectives is to be accessible to all political scientists (and
    even politically sophisticated nonacademics), so the ideal amount
    of symbolic notation is zero.}
  
  We reduced the length of the paper by nearly a third, mostly by
  cutting technical details about Bayesian Model Averaging.  The
  current version of the manuscript is only 18 pages and its main text
  is 15 pages.  We also removed many equations and mathematical
  symbols whenever possible.  The paper overall is considerably less
  mathematical.
  
\item {\it Second, there is some verbal overclaiming in the paper that
    needs to be toned down.  You'll need to back off the claim that
    "Formal Bayesian model averaging has not been used in political
    science..."  The reviewers and editors agree that the claim is not
    true, and in any case it is contradicted by footnote 7.}
  
  We have revised the manuscript to address this point.
  
\item {\it In addition, you'll need to acknowledge that you have a
    ``too many parameters problem'' and that model averaging does not
    solve the problem (unless you can conclusively refute this
    claim).}
  
  We believe we can ``conclusively refute this claim.''  The purpose
  of our method is not to ``estimate the impact of 27 covariates and
  $X_i$ on bad vote rates for Bush and Gore'' as Referee~1 states.
  Rather, our goal is to \emph{predict} the number of bad votes that
  were cast for Bush. These two are fundamentally different: the first
  is a problem of causal inference, while the second is a problem of
  the predictive inference. The fundamental theoretical property of
  Bayesian model averaging concerns predictive inference and not
  causal inference.  We have tried to make this much clearer in the
  current version.
  
  To be more specific, in predictive problems (but not causal
  problems) where we do not know the true model, estimating a model
  with ``all'' variables one can think of will almost surely generate
  bias and inefficiency relative to some subset.  In particular,
  including irrelevant variables may not bias causal inferences but
  they will bias predictive inferences and so should be avoided.  This
  is the conclusion of the large literature on model (or variable)
  selection (e.g., stepwise methods, Cp criterion, etc.), most of
  which don't make much sense in making causal inferences.
  
  A key result in this literature is that BMA is known to perform
  better than all standard variable selection procedures because it
  takes into account model uncertainty rather than trying to select
  the ``one best model.''  Hoeting et al (1999, Statistical Science)
  and Madigan and Raftery (1994, JASA) among others have shown that
  BMA almost never puts much weight on the model with all covariates,
  or even one with many, and that the average of the submodels is
  optimal.  Indeed, even if the true model has 2000 variables --- and
  so with 67 observations it can't be estimated, and for predictive
  purposes some model with a subset of variables must be chosen --- a
  BMA that averages over any relevant set of submodels will outperform
  any individual model in the set, even though the truth is obviously
  not one of the models estimated.
  
  As the referee correctly points out, we have not explored the entire
  model space. Indeed, in most applications, the entire model space is
  infinite and so exploring the entire model space is impossible.  In
  our application, any finite number of models does not represent the
  entire model space.  One can collect more covariates and include
  them in the model, add more interactions and higher order polynomial
  terms, use different ecological inference models, and so on.  This
  implies, however, one can never explore the entire model space.
  Bayesian model averaging (BMA), therefore, must condition on a
  finite subset of the entire model space.  This is a limitation of
  course and the revised manuscript now highlights it.
  
  However, we disagree with the referee's point that this invalidates
  BMA.  If the referee's criticism is correct, every standard
  statistical analysis is invalid since it conditions on only
  \emph{one} model.  At least BMA enables one to specify multiple
  models.  For example, almost all applications of ecological
  inference in the literature use only one model without any
  covariates.  The referee's suggestion to ``consider EI models that
  include $X_i$ only'' would be subject to the same criticism since it
  conditions on a single model.
  
  Although our BMA analysis does not explore the entire model space,
  since that is impossible, it is superior to any of the standard
  approaches.  In particular, BMA is better at estimating a predictive
  quantity than any submodel being averaged over, even if the true
  model is {\it outside} the set of submodels being averaged over
  (e.g., Madigan and Raftery, 1994 JASA).  (Almost the same result
  exists in the literature on committee methods (e.g., Bishop, 1995).)
  Our BMA approach is known to be better than any submodel that is
  averaged over in our analysis including the one suggested by the
  referee.  With the methods we introduced in this paper, making it
  possible to use BMA with ecological inference, these advances would
  not be available.
  
  Since the entire model space is infinite, it is always possible that
  someone may finds a new submodel to include in a BMA.  No one has
  suggested a plausible story, and accompanying model, that we have
  excluded, and that produces markedly different inferences and has a
  high probability of being correct, but we are certainly open to be
  proved wrong if someone finds such a model.  Of course, every
  empirical analysis is vulnerable to this criticism that there might
  be a better model that was not considered in the original analysis.
  
  Finally, to test our setup in response to these questions, we have
  subsequently estimated several three and four variable ecological
  inference models.  Although we found that some of these had high
  enough estimated weights to be contribute in a meaningful way in the
  ultimate BMA computation, they did not change our substantive
  results in any appreciable way. We explain this in the paper.

\item {\it It would also be valuable simply to say outright that it
    seems unlikely that of 680 invalid ballots, 537 of them would
    have been for Bush.}
  
  This may be true, but we wanted to stay away from making prior
  assumptions like these.  No one had any evidence ex ante about who
  the absentee voters were.  Some thought they were mostly from the
  military.  Others thought they were Jewish voters casting ballots in
  Israel.  No prior studies existed, no surveys had been conducted, no
  journalists had contacted individual absentee voters, etc.
  Moreover, even if we knew who the absentee voters were, we would
  have no prior information about which of the absentee voters cast
  the bad ballots; that is after all the subject of our sgudy.  Our
  given task was to produce an estimate of the probability of a Gore
  victory without making implicit assumptions.
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\begin{center}
  {\bf \Large Point-By-Point Reply to the Associate Editor}
\end{center}

We begin by thanking Henry for his detailed comments in this memo and
several previously.  We believe we have addressed all of these
comments in our revised manuscript and that in so doing we have
improved our paper significantly.  In what follows, the original
comments appear in \emph{italic type}; our replies and comments are in
roman type.

\bigskip
\noindent {\bf Major Comments of and reply to Referee~1}

\begin{enumerate}
  
\item {\it Given this strong concern about the use of Bayesian
    averaging and given our own predilection for a shorter and
    somewhat simpler paper, we believe that it would be much better to
    structure the paper as suggested by reviewer number 1:
    \begin{quote}
      ``For a revision of this paper, I would recommend sticking with
      the bounds analysis which is excellent and nicely written.  I
      would also keep the material on Republican pressure \ldots.
      Furthermore, I would consider EI models that include Xi only along
      with varying priors or no priors at all.''
    \end{quote}
    We believe that the paper could be considerably shortened and
    tightened by completely cutting pages 12-15 on Bayesian model
    averaging.  Instead, we would suggest an approach that would face
    straightforwardly the problem of too little data for the number of
    parameters that should be estimated in a full model and that would
    make the following points.}
  
  We addressed this concern in our reply to Referee~1 below, the
  editor above, as well as in the revised manuscript.  In particular,
  we have shortened the section on Bayesian model averaging
  considerably and greatly reduced its mathematical content.  The
  revised manuscript is now 18 pages long (including the Appendix and
  references) instead of the original length of 28 pages. We did not
  entirely eliminate our Bayesian model averaging analysis because it
  is the core of the analysis we did for the {\it New York Times} and
  the main contribution of the paper.  We also believe that our
  application of Bayesian Model Averaging is based on a solid
  methodological ground, on which we further elaborate below.
  
  Moreover, although we all like the bounds because they make no
  statistical assumptions, they provide very little information about
  the quantity of interest, which is the probability that Gore won the
  election.  For that quantity, \emph{all} the bounds tell is is that
  this probability is not zero.  They provide no other information.
  The only way to learn more about the quantities of interest are to
  move to model-based analyses.
  
  Most importantly, the purpose of our method is not to ``estimate the
  impact of 27 covariates and $X_i$ on bad vote rates for Bush and
  Gore'' as Referee~1 states. Rather, our goal is to predict the
  number of bad votes that was cast for Bush.  These two are
  fundamentally different: The first is a problem of causal inference,
  while the second is a problem of the predictive inference. The
  fundamental theoretical property of Bayesian model averaging
  concerns predictive inference and not causal inference.  We have
  tried to make this much clearer in the current version.
  
  To be more specific, in predictive problems (but not causal
  problems) where we do not know the true model, estimating a model
  with ``all'' variables one can think of will almost surely generate
  bias and inefficiency relative to some subset.  In particular,
  including irrelevant variables may not bias causal inferences but
  they will bias predictive inferences and so should be avoided.  This
  is the conclusion of the large literature on model (or variable)
  selection (e.g., stepwise methods, Cp criterion, etc.), most of
  which don't make much sense in making causal inferences.
  
  A key result in this literature is that BMA is known to perform
  better than all these standard variable selection procedures because
  it takes into account model uncertainty rather than trying to select
  the ``one best model.''  Hoeting et al (1999, Statistical Science)
  and Madigan and Raftery (1994, JASA) among others have shown that
  BMA almost never puts much weight on the model with all covariates,
  or even one with many covariates, and that the average of the
  submodels is optimal.  Indeed, even if the true model has 2000
  variables --- and so with 67 observations it can't be estimated, and
  for predictive purposes some model with a subset of variables must
  be chosen --- a BMA that averages over any relevant set of submodels
  will outperform any individual model in the set, even though the
  truth is obviously not one of the models estimated.
  
  As the referee correctly points out, we have not explored the entire
  model space. Indeed, in most applications, the entire model space is
  infinite and so no finite number of models could represent it fully.
  One can collect more covariates and include them in the model, add
  more interactions and higher order polynomial terms, use different
  ecological inference models, and so on.  Bayesian model averaging
  (BMA), therefore, must condition on a finite subset of the entire
  model space.  This is a limitation of course and the revised
  manuscript now highlights it.
  
  However, we disagree with the referee's point that this invalidates
  BMA. If the referee's criticism is correct, every standard
  statistical analysis is invalid since it conditions on one model.
  For example, almost all applications of ecological inference
  analysis use only one model without any covariates. Such an approach
  is invalid by this logic since it does not explore the entire model
  space.  The referee's suggestion to ``consider EI models that
  include $X_i$ only'' would be subject to the same criticism since it
  conditions on a single model.
  
  Although our BMA analysis does not explore the entire model space,
  since that is impossible, it is superior to any of these standard
  approaches.  BMA is known to be better at estimating a predictive
  quantity than any submodel being averaged over, even if the true
  model is {\it outside} the set of submodels being averaged over
  (e.g., Madigan and Raftery, 1994 JASA).  (Almost the same result
  exists in the literature on committee methods (e.g., Bishop, 1995).)
  With the methods we introduced in this paper, making it possible to
  use BMA with ecological inference, these advances would not be
  available.
  
  Since the entire model space is infinite, it is always possible that
  someone may finds a new submodel to include in a BMA.  No one has
  suggested a plausible story, and accompanying model, that we have
  excluded, and that produces markedly different inferences and has a
  high probability of being correct, but we are certainly open to be
  proved wrong if someone finds such a model.  Of course, every
  empirical analysis is vulnerable to this criticism that there might
  be a better model that was not considered in the original analysis.
  
  Finally, to test our setup in response to these questions, we have
  subsequently estimated several three and four variable ecological
  inference models.  Although we found that some of these had high
  enough estimated weights to be contribute in a meaningful way in the
  ultimate BMA computation, they did not change our substantive
  results in any appreciable way.  We explain this in the paper.

\item {\it First, a very simple back of the envelope calculation
    suggests that if 680 of the 2411 late overseas ballots were ruled
    illegal, and if they had the same proportion of Bush voters as all
    other late overseas ballots (65.3\%), then Bush would lose 444
    votes and Gore would lose 236 votes for a net loss to Bush of 208
    votes which would have given Bush a margin of (537-208 = 229).
    (This figure, by the way, is very close to the 251 in table 5
    which comes from the Bayesian averaging method.)  This point could
    be made when Table 1 is discussed.
    
    This point leads us to ask if we can figure out anything about the
    likelihood that Gore might have won.  After all, the preceding is
    just a point estimate which might vary depending upon the other
    factors which affected these 680 ballots.  One way Gore could have
    won is that even if the illegal ballots are a true random sample
    of the total late overseas ballots, the illegal ballots could be
    larger or smaller because of sample variability.  It is a little
    tricky calculating sampling error in this case (because it is
    sampling from a decidedly finite population), but we might presume
    that the sampling error is something like what we would have for a
    poll of 680 people which would be roughly plus or minus 4\% which
    would lead to 95\% confidence bounds of roughly 412 and 476 for
    Bush's loss of votes.  This would translate into roughly a net
    loss for Bush of about 176 to 240.  Still not enough to make Gore
    the winner --- although it does get us closer. 
    
    Thus, this calculation leads us to assume that there is only a
    very small chance that Gore might have won.  However, this
    approach neglects the fact that we know more about the illegal
    overseas absentee ballots.  We also know the county they came
    from, and we even know the characteristics of the voters who cast
    them.  Thus, (1) variation could occur because the illegal late
    overseas ballots came disproportionately from counties that were
    highly pro-Bush or (2) variation could occur because the
    characteristics of the late overseas voters were such that they
    might have been disproportionately pro-Bush.  Hence, it is at
    least possible that these ballots made the difference.}
   
  
  This may be true, but we wanted to stay away from making prior
  assumptions like these.  No one had any evidence ex ante about who
  the absentee voters were.  Some thought they were mostly from the
  military.  Others thought they were Jewish voters casting ballots in
  Israel.  No prior studies existed, no surveys had been conducted, no
  journalists had contacted individual absentee voters, etc.
  Moreover, even if we knew who the absentee voters were, we would
  have no prior information about which of the absentee voters cast
  the bad ballots; that is after all the subject of our sgudy.  Our
  given task was to produce an estimate of the probability of a Gore
  victory without making implicit assumptions.
  
\item {\it At this point, it might be worth noting that what would be
    required for a tie would be for disqualification of the 680
    illegal late absentee votes to lead to a 537 vote swing --- that
    would require that the difference in Bush and Gore voting
    percentages would have to be (537/680 = 79\%).  The only way this
    could happen would be for Bush to get about 90\% of the votes and
    Gore to get about 10\% (for a difference of about 80\% as
    required).  (This point is made by Reviewer number Three.)  This
    seems very unlikely, but it is worth looking to see if it is
    possible. }

  We added this point to the paper.
  
\item {\it Then the paper could talk about statistical modeling, but
    instead of talking about Bayesian model averaging, it could simply
    note that there are many ways to model things and that one way to
    get a fix on what is going on is to estimate a number of different
    simple models to see how much the simple figures would vary if
    different covariates were used.  This could be presented as
    sensitivity testing instead of as a way to get ``precise''
    probabilities.  Section 3.2 could do this but with the Bayesian
    model averaging deleted.  (Note that Table 7 does something like
    this.  Indeed, Table 7 suggests why Bayesian model averaging is
    probably not as good an idea as simply showing how different
    models lead to different results.) 
    
    The empirical results could then be presented but with
    representative models described with different point predictions.
    It could be noted that as it turns out, it seems VERY unlikely
    that the 680 votes had anything like a 90\% Bush and 10\% Gore
    break.
  
    Finally, Table 5 could be presented to show that in conjunction
    with other things, the absentee votes might have made a
    difference.  The entry in the table for the impact of the illegal
    overseas ballots could be described as roughly some range from the
    preceding work or it could simply take use the
    back-of-the-envelope calculation described above.  Or it could
    take the results from the ecological inference without covariates.
    Or it could take values for different models as in Table 7.}
  
  We are hesitant to take this suggestion.  Most importantly, the New
  York Times asked us to provide a single inference, i.e., a point
  estimate and confidence interval. Presenting a set of many different
  results from a variety of models was simply not an option to us.  We
  do highlight the different results from different models in our
  paper somewhat more than in the previous version, but leaving it as
  different results being produced by different models produces no
  probability distribution over the quantity of interest, since the
  reader has no way to weigh the different models.  We therefore
  provide the reader one way, which is with BMA.  BMA is known to be
  the best way to provide a single inference in the presence of model
  uncertainty.  The statistical literature supports this claim by
  showing that the Bayesian model averaging produces the inference
  better than the inference resulting from any of the single models
  that are averaged over, no matter whether the true model is inside
  or outside of the set of models considered.  We tried to make this
  point much clearer in the revised manuscript.  Please also see our
  point-by-point reply to referees.

\end{enumerate}

\bigskip
\noindent {\bf Specific Comments}

We implemented almost all of these suggestions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\begin{center}
  {\bf \Large Point-By-Point Reply to Referee~1}
\end{center}

We begin by thanking Referee~1 for his/her careful reading of our
manuscript and many helpful comments. We believe we have addressed all
of these comments in our revised manuscript and that in so doing we
have improved our presentation significantly.  In what follows, the
original comments appear in \emph{italic type}; our replies and
comments are in roman type.

\bigskip
\noindent {\bf Major Comments of and reply to Referee~1}

\begin{enumerate}
  
\item {\it Using 67 observations, the author wants to estimate the
    impact of 27 covariates and $X_i$ on bad vote rates for Bush and
    Gore.  Each covariate requires 2 estimated parameters as in the
    ``Except [for] the first three models $\cdots$'' clause of
    footnote 9.  Roughly, this means that there are 56 parameters to
    estimate.  $67-56=11$, and this is a very, very low number. This
    paper, therefore, has almost no data to bear on the quantities it
    wants to estimate.  This is not the fault of the authors.  The bad
    votes problem is just one that is practically data-less.}
  
  The purpose of our method is NOT to ``estimate the impact of 27
  covariates and $X_i$ on bad vote rates for Bush and Gore.'' Rather,
  our goal is to predict the number of bad votes that was cast for
  Bush. These two are fundamentally different: the first is a problem
  of causal inference, while the second is a problem of the predictive
  inference. The fundamental theoretical property of Bayesian model
  averaging concerns predictive inference and not causal inference.
  We have tried to make this much clearer in the current version.
  
  To be more specific, in predictive problems (but not causal
  problems) where we do not know the true model, estimating a model
  with ``all'' variables one can think of will almost surely generate
  bias and inefficiency relative to some subset.  In particular,
  including irrelevant variables may not bias causal inferences but
  they will bias predictive inferences and so should be avoided.  This
  is the conclusion of the large literature on model (or variable)
  selection (e.g., stepwise methods, Cp criterion, etc.), most of
  which don't make much sense in making causal inferences.
  
  A key result in this literature is that BMA is known to perform
  better than all these standard variable selection procedures because
  it takes into account model uncertainty rather than trying to select
  the ``one best model.''  Hoeting et al (1999, Statistical Science)
  and Madigan and Raftery (1994, JASA) among others have shown that
  BMA almost never puts much weight on the model with all covariates,
  even when that is an option, and that the average of the submodels
  is optimal.  Indeed, even if the true model has 2000 variables --
  and so with 67 observations it can't be estimated, and for
  predictive purposes some model with a subset of variables must be
  chosen -- a BMA that averages over any relevant set of submodels
  will outperform any individual model in the set, even though the
  truth is obviously not one of the models estimated.  
 
\item {\it If I were reviewing a paper that used a least squares model
    with 67 observations to estimate 56 parameters, I would not trust
    its answers at all.  In this case, the situation is even harder.
    The models used in the paper are non-linear and use aggregate
    data.
    
    The author tries to get around this problem by using model
    averaging.  Rather than one EI model with 56 estimated parameters
    (or more, for intercepts and variances) the author considers a
    collection of EI models that require only a few parameters.  This
    does not eliminate the problem of estimating 56 parameters with 67
    observations.  Furthermore, the author does averaging over a tiny
    subset of possible models.  There are roughly 228 (or maybe 256)
    models over which the author should be averaging.  However, he
    considers only 31 of these.  31/228 is basically zero, and so it
    follows that the author has not explored the model space. 
    
    Will the author's approach, which calls for using 31 small models,
    be sufficient to cover the entire model space?  I cannot imagine
    so.  There are no arguments for this in the paper.  The author
    claims on page 10 that the reduction to 31 is fine, but there is
    no evidence showing this to be the case.}
  
  As the referee correctly points out, we have not explored the entire
  model space. Indeed, in most applications, the entire model space is
  infinite. In our application, therefore, neither 31 nor 228 models
  represent the entire model space.  One can collect more covariates
  and include them in the model, add more interactions and higher
  order polynomial terms, use different ecological inference models,
  and so on.  This implies, however, one can never explore the entire
  model space.  Bayesian model averaging (BMA), therefore, must
  condition on a finite subset of the entire model space.  This is a
  limitation of course and the revised manuscript now highlights it.
  
  However, we disagree with the referee's point that this invalidates
  our BMA analysis. If the referee's criticism is correct, every
  standard statistical analysis is invalid since it conditions on one
  model.  For example, almost all applications of ecological
  inference analysis use only one model without any covariates. Such
  an approach is invalid since it does not explore the entire model
  space.  The referee's suggestion to ``consider EI models that
  include $X_i$ only'' would be subject to the same criticism since it
  conditions on a single model.
  
  Although our BMA analysis does not explore the entire model space,
  since that is impossible, it is superior to any of these standard
  approaches.  This conclusion is based on the general theoretical
  properties of BMA. The BMA analysis is better at estimating a
  predictive quantity than any submodel being averaged over, even if
  the true model is {\it outside} the set of submodels being averaged
  over (e.g., Madigan and Raftery, 1994 JASA).  Note that almost the
  same result exists in the literature on committee methods (e.g.,
  Bishop, 1995).  That is, our BMA approach is better than any
  submodel that is averaged over in our analysis including the one
  suggested by the referee.
  
  Since the entire model space is infinite, it is always possible that
  someone finds a new submodel to include in a BMA.  No one has
  suggested a plausible story, and accompanying model, that we have
  excluded but we are certainly open to be proved wrong if someone
  finds such a model.  Of course, every empirical analysis is
  vulnerable to this criticism that there might be a better model that
  is not considered in the original analysis.
  
  Finally, to test our setup in response to these questions, we have
  subsequently estimated several three and four variable ecological
  inference models.  Although we found that some of these had high
  enough estimated weights to be contribute in a meaningful way in the
  ultimate BMA computation, they did not change our substantive
  results in any appreciable way.  We explain this in the paper.
  
\item {\it It also needs to be honest about priors.  When a Bayesian
    statistical method has 67 observations, priors are going to matter
    a huge amount, even if only 5 parameters were estimated.  The
    author on page 12 says that priors should ``include all
    information available about a quantity of interest'' but then goes
    on to use ``standard independent priors.'' These standard priors
    have nothing to do with information.  Any prior that is standard
    cannot reflect information unique to a given problem, else it
    would not be standard.}
  
  There are two kinds of prior that we specify in our BMA analysis.
  One on the model probability and the other on the distribution of
  parameters. We use noninformative priors for the model probability
  by not favoring any particular model a priori. This is a standard
  approach in BMA since the whole purpose of BMA is to let the data
  tell you which model should be preferred.  This choice is not
  normally seen as controversial. For the model parameters, we use the
  standard prior presented and examined in King (1997). This choice
  might have more of an effect.  Thus, following standard Bayesian
  practice, we conduct sensitivity analyses (see Appendix B.2) and
  find that in fact the prior specification has little influence on
  our conclusions.  We have clarified this in the Appendix.
  
\item {\it For a revision of this paper, I would recommend sticking
    with the bounds analysis which is excellent and nicely written.}
  
  The bounds analysis is appealing since it does not impose any
  statistical assumptions.  However, the public is apparently
  uninterested in the limited information it provides.  All it says is
  that it is possible that Gore could have won.  The bounds alone do
  not answer the question posed by the Times.  This is of course why
  the field of ecological inference did not end in 1953 with Duncan
  and Davis' discovery of the bounds, and why the bounds alone are
  used in very few studies studies that apply ecological inference
  even in academia, but the contribution of the bounds to our quantity
  of interest here is even smaller since the quantity of interest is
  not the fractions but rather the probability that Gore really won.
  Unfortunately, the bounds only tell us that that probability is not
  0.  It says nothing else.
  
  The Times reporters repeatedly told us that they needed a point
  estimate, and that they could deal with confidence intervals (or
  margins of error) but not the bounds.  Our approach provides a point
  estimate that takes into account all reasonable models that were
  suggested to us at that time.  It has limitations, but it is better
  than any feasible alternative suggested at the time or since in
  providing what the public and newspaper needed (a point estimate and
  uncertainty estimate).
 
\item {\it I would also keep the material on Republican pressure,
    although the conclusions the author draws from this are overstated
    in some places.  The Republicans choose where to pressure, so
    arguing that they were successful (see page 19) is hard to
    justify.}
  
  In the revised manuscript, we have acknowledged this possible
  selection bias and added a qualification.  However, for there to
  have been selection bias, the Republicans would have had to choose
  counties to pressure based on their success over and above what
  could be predicted based on Republican strength and the other
  variables we measured.  Since prior evidence on where pressure
  would be successful did not exist, selection bias is unlikely.
\end{enumerate}

\bigskip
\noindent {\bf Minor Comments}

We implemented almost all of these suggestions.

% \begin{enumerate}
% \item {\it The first sentence of the paper is awkward.  ``Yet, they
%     clearly determined the outcome of the election.'' This can be said
%     of every anomaly from Florida given the tight margin.}
  
% \item {\it ``Our results give ...'' on page 3.  Replace ``give'' with
%     ``estimate.'' Statistical results can do not better than this.}
  
% \item {\it ``seen as remarkable ...'' is not remarkable.  The
%     probability that all voters in Florida like Gore more than Bush
%     has positive probability, the probability that Katherine Harris
%     decided the election has positive probability, and so on.}
  
% \item {\it ``In counties more favorable to Democrats ...'' examples
%     would be nice.}
  
% \item {\it Table 2 has 3 columns and Table 3 has 2 columns.  The
%     transition is awkward.}
  
% \item {\it Page 7 should cite Duncan and Davis.}
  
% \item {\it The Baker County example on page 8 is striking and could be
%     played up more.}
  
% \item {\it ``... knowing for certain who won the 2000 election'' We
%     all know that Bush won since winning is a legal matter.  What the
%     author means is knowing if more voters were cast for Bush than
%     Gore in Florida.}
  
% \item {\it Section 4.3 has too many comments that look causal.  See my
%     comments above.  ``if all American laws had been followed'' is not
%     the point here.  Voting laws are almost entirely local, so the
%     issue for Florida votes is Florida laws.}
% \end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\begin{center}
  {\bf \Large Point-By-Point Reply to Referee~2}
\end{center}

We begin by thanking Referee~2 for his/her careful reading of our
manuscript and many helpful comments. We believe we have addressed all
of these comments in our revised manuscript and that in so doing we
have improved our presentation significantly.  In what follows, the
original comments appear in italic type; our replies and comments are
in roman type.

\bigskip

\noindent {\bf Major Comments of and reply to Referee~2}

\begin{enumerate}
\item {\it This paper, like some others I have seen, seems to assume
    that any question touching on the 2000 presidential vote in
    Florida is inherently fascinating.  But the question here is
    whether voiding 680 illegal ballots would have reversed a 537-vote
    margin.  For that to be the case, the illegal ballots would have
    had to split about 90-10 for Bush.  How likely is a 90-10 split in
    a 50-50 state?  For that matter, how likely is a 90-10 split in
    presidential votes in ANY social group?  Unless they happened to
    be a boatload of Christian fundamentalist missionaries, not very.
    We don't need ecological inference, Bayesian model averaging, or
    high-priced political science of any kind to conclude that the
    authors' question is not really all that interesting.}
  
  We are hesitant to discuss whether the question posed by the NYT is
  interesting since it is purely a matter of subjective judgment.
  Rather, our goal was to give a scientific answer to the question
  posed. Here, we merely explain why the NYTs and their readers
  thought this question important and interesting and wrote the full
  four page article --- the longest since the Watergate. The important
  thing to note here is that we are looking at the Bush's vote share
  among ``bad'' overseas ballots rather than ``all'' overseas ballots.
  More than 25 NYT journalists spent six months and gathered massive
  qualitative evidence that the Bush campaign put significant amount
  of pressure on local electoral officials to count those ballots that
  were likely to be cast for Bush (e.g., military votes).  Based on
  this evidence, they concluded that it may be possible that most of
  illegally counted overseas ballots might have been cast for Bush,
  and asked us to investigate such possibility.  Our results contrast
  sharply with the grounds on which the Supreme Court case that
  ultimately decided the election was justified --- treating voters
  equally under the law.  The count in Florida was stopped by the
  Court supposedly to keep treatment equal in all counties, but yet
  the absentee voters in different counties were clearly not treated
  equally.
  
\item {\it The authors evade this problem partly through misdirection
    and partly through purple prose.  For example, on page 3, the
    estimated probability that Gore should have won "is small, but we
    know with mathematical certainty that it is greater than zero--a
    conclusion that can only be seen as remarkable for the world's
    premier democracy."  What does this mean?
    
    Since the number of invalid ballots was (according to the New York
    Times) larger than the vote margin, and since we don't know how
    the invalid ballots were cast, it is impossible in principle for
    ANY statistical analysis to assign a probability of zero (or one)
    to the proposition that Gore should have won.  I suppose that is a
    ``mathematical certainty,'' but it is not a very interesting one,
    and it owes nothing to the authors' analysis.  Nor is it very
    remarkable.  Any coherent (i.e., Bayesian) worldview would, I
    think, have to assign non-zero (albeit VERY small) probability to
    the proposition that the candidate won EVERY presidential election
    in American history due to erroneous or fraudulent vote counts.
    The possibility doesn't keep me awake at night.}
  
  By ``mathematical certainty,'' we mean that the data alone (without
  any statistical or other assumption) cannot eliminate the
  possibility that Gore might have won the election. This is not
  because ``the number of invalid ballots was larger than the vote
  margin'' as the referee suggests.  Indeed, in theory the analysis of
  bounds can eliminate the possibility of Gore's victory: the width of
  bounds depends on the data. Since this analysis does not impose any
  statistical assumption, we believe that it is important to stress
  its conclusion.  We toned down our claims and tried to put them in
  the context of these good points made by the referee.
  
\item {\it When I first saw the paper I was naturally intrigued by the
    claim that "Formal Bayesian model averaging has not been used in
    political science."  I thought that scholars had used it over the
    past half-dozen years.  It turns out (footnote 7) that they used
    "an approximation to formal Bayesian model averaging."  Why an
    "approximation"?  The authors never say, but I conjecture from
    some discussion in Appendix A that what they have in mind is that
    previous work employed the BIC statistic to index the relative
    likelihood of alternative models, whereas they use a Laplace
    approximation.  (Isn't an "approximation" too?)  The Laplace
    approximation is, indeed, more appropriate for their application,
    but identical for others' (i.e., for ordinary regression models).
    So the primary methodological selling point of the paper seems to
    me to reduce, essentially, to tendentious self-promotion.}
  
  The Laplace approximation provides a better way to approximate the
  marginal likelihood, which is analytically intractable (DiCiccio et
  al., 1997 JASA).  Even though BIC is a much inferior one
  approximation to BMA, we agree with the referee's point that it is
  nonetheless still an approximation to BMA.  We have removed our
  claim and changed the paper accordingly.
  
\item {\it What seems most striking about the statistical analysis (pages
  9-14) is the high ratio of wind-up to substance.  The authors
  provide nice general descriptions of Gary King's EI model and of
  Bayesian model averaging, but make NO mention in the text of what
  models they actually estimated (these are listed very
  telegraphically in a footnote) or what the results were (even in the
  appendices)!  This must come close to absolute zero with respect to
  a methodological standard that Gary King has admirably set forth in
  his work: make it clear what the data are and how you got from the
  data to the conclusions.}

To keep the paper as short as the editors want, we were unable to put
much description of this in the text.  However, we have added enough
detail so that anyone with access to the data would be able to
replicate our results.  We will also provide a replication dataset
upon publication.

\item {\it The model space requires much more in the way of
    substantive justification than it gets here.  I see no need to
    consider every logically possible combination of the 27 available
    covariates, but neither does it make sense to limit the analysis
    to bivariate models.  Saying more about what the variables
    actually measure, why they might be relevant, and which (if any)
    produce significant results when considered in isolation and in
    limited, substantively sensible combinations would be a good start
    on a more interesting and potentially convincing analysis.
    Whether this problem deserves that sort of work is unclear to me,
    but that sort of work would, in my view, be necessary for the
    statistical analysis to fly.}
 
  We hesitate to speculate about causal inferences from these data and
  would not interpret the coefficients on our covariates as
  approximation any kind of causal inference.  Our goal is prediction,
  and we are willing to include in the set of models we average over
  any variable or model that anyone might suggest could plausibly
  change our results.  Thus far, we have included all such models.
\end{enumerate}

\end{document}


